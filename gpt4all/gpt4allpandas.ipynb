{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ySAMvGyGfI3",
        "outputId": "23ae21d2-b320-46c4-e81a-ab04993ca27c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed gpt4pandas.\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "package_name = \"gpt4pandas\"\n",
        "\n",
        "try:\n",
        "    # Attempt to install the package using pip\n",
        "    subprocess.check_call([\"pip\", \"install\", package_name])\n",
        "    print(f\"Successfully installed {package_name}.\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    # Handle the error if the installation fails\n",
        "    print(f\"Error: Failed to install {package_name}.\")\n",
        "else:\n",
        "    # Code to be executed if the installation is successful\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from gpt4pandas import GPT4Pandas\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import urllib\n",
        "import sys\n",
        "\n",
        "# If there is no model, then download one\n",
        "# These models can be automatically downloaded, uncomment the model you want to use\n",
        "# url = \"https://huggingface.co/ParisNeo/GPT4All/resolve/main/gpt4all-lora-quantized-ggml.bin\"\n",
        "# url = \"https://huggingface.co/ParisNeo/GPT4All/resolve/main/gpt4all-lora-unfiltered-quantized.new.bin\"\n",
        "# url = \"https://huggingface.co/eachadea/legacy-ggml-vicuna-7b-4bit/resolve/main/ggml-vicuna-7b-4bit-rev1.bin\"\n",
        "url = \"https://huggingface.co/eachadea/ggml-vicuna-13b-4bit/resolve/main/ggml-vicuna-13b-4bit-rev1.bin\"\n",
        "model_name  = url.split(\"/\")[-1]\n",
        "folder_path = Path(\"models/\")\n",
        "\n",
        "model_full_path = (folder_path / model_name)\n",
        "\n",
        "# ++++++++++++++++++++ Model downloading +++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "# Check if file already exists in folder\n",
        "if model_full_path.exists():\n",
        "    print(\"File already exists in folder\")\n",
        "else:\n",
        "    # Create folder if it doesn't exist\n",
        "    folder_path.mkdir(parents=True, exist_ok=True)\n",
        "    progress_bar = tqdm(total=None, unit=\"B\", unit_scale=True, desc=f\"Downloading {url.split('/')[-1]}\")\n",
        "    # Define callback function for urlretrieve\n",
        "    def report_progress(block_num, block_size, total_size):\n",
        "        progress_bar.total=total_size\n",
        "        progress_bar.update(block_size)\n",
        "    # Download file from URL to folder\n",
        "    try:\n",
        "        urllib.request.urlretrieve(url, folder_path / url.split(\"/\")[-1], reporthook=report_progress)\n",
        "        print(\"File downloaded successfully!\")\n",
        "    except Exception as e:\n",
        "        print(\"Error downloading file:\", e)\n",
        "        sys.exit(1)\n",
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "# Load a sample dataframe\n",
        "data = {\n",
        "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
        "    \"Age\": [25, 30, 35],\n",
        "    \"City\": [\"New York\", \"Paris\", \"London\"],\n",
        "    \"Salary\": [50000, 60000, 70000],\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Initialize the GPT4Pandas model\n",
        "model_path = \"models/\"+model_name\n",
        "gpt = GPT4Pandas(model_path, df, verbose=False)\n",
        "\n",
        "print(\"Dataframe\")\n",
        "print(df)\n",
        "# Ask a question about the dataframe\n",
        "question = \"What is the average salary?\"\n",
        "print(question)\n",
        "answer = gpt.ask(question)\n",
        "print(answer)  # Output: \"mean(Salary)\"\n",
        "\n",
        "# Ask another question\n",
        "question = \"Which person is youngest?\"\n",
        "print(question)\n",
        "answer = gpt.ask(question)\n",
        "print(answer)  # Output: \"max(Age)\"\n",
        "\n",
        "# Set a new dataframe and ask a question\n",
        "new_data = {\n",
        "    \"Name\": [\"David\", \"Emily\"],\n",
        "    \"Age\": [40, 45],\n",
        "    \"City\": [\"Berlin\", \"Tokyo\"],\n",
        "    \"Salary\": [80000, 90000],\n",
        "}\n",
        "new_df = pd.DataFrame(new_data)\n",
        "print(\"Dataframe\")\n",
        "print(new_df)\n",
        "\n",
        "gpt.set_dataframe(new_df)\n",
        "question = \"What is salary in Tokyo?\"\n",
        "print(question)\n",
        "answer = gpt.ask(question)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJYAFgAiHRDH",
        "outputId": "842baad3-5ef0-4c80-b27c-a97433517543"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading ggml-vicuna-13b-4bit-rev1.bin: 100%|█████████▉| 8.13G/8.14G [01:08<00:00, 138MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded successfully!\n",
            "Dataframe\n",
            "      Name  Age      City  Salary\n",
            "0    Alice   25  New York   50000\n",
            "1      Bob   30     Paris   60000\n",
            "2  Charlie   35    London   70000\n",
            "What is the average salary?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rDownloading ggml-vicuna-13b-4bit-rev1.bin: 8.14GB [05:09, 138MB/s]                            "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The average salary is 55,000.\n",
            "Which person is youngest?\n",
            "Alice is the youngest.\n",
            "Dataframe\n",
            "    Name  Age    City  Salary\n",
            "0  David   40  Berlin   80000\n",
            "1  Emily   45   Tokyo   90000\n",
            "What is salary in Tokyo?\n",
            "90000.\n"
          ]
        }
      ]
    }
  ]
}